import pandas as pd
import numpy as np
import matplotlib.pyplot as plt 
import seaborn as sns 

%matplotlib inline
sns.set_style('whitegrid')
plt.style.use('fivethirtyeight')

# read file 
data = pd.read_csv("heart.csv")
data.head()

# Exploratory Data Analysis
pd.set_option('display.float',"{:.2f}".format)
data.describe()

data.target.value_counts().plot(kind='bar',color=['salmon','lightblue'])

# missing values
data.isnull().sum()

catagorical_val=[]
continuous_val=[]
for column in data.columns:
    print('================================================')
    print(f'{column}:{data[column].unique()}')
    if len(data[column].unique())<=10:
        catagorical_val.append(column) 
    else:
        continuous_val.append(column)

plt.figure(figsize = (15,15))
for i , column in enumerate(catagorical_val,1):
    plt.subplot(3,3,i)
    data[data['target'] == 0][column].hist(bins = 35,color = 'blue',label = 'have  heart disease=NO',alpha = 0.7)
    data[data['target'] == 1][column].hist(bins = 35,color = 'red',label = 'have  heart disease=YES',alpha = 0.7)
    plt.legend()
    plt.xlabel(column)



plt.figure(figsize = (15,15))
for i , column in enumerate(continuous_val,1):
    plt.subplot(3,3,i)
    data[data['target'] == 0][column].hist(bins = 35,color = 'blue',label = 'have  heart disease=NO',alpha = 0.7)
    data[data['target'] == 1][column].hist(bins = 35,color = 'red',label = 'have  heart disease=YES',alpha = 0.7)
    plt.legend()
    plt.xlabel(column)



# create another figure 
plt.figure(figsize=(10,8))
# scatter with positive examples
plt.scatter(data.age[data.target==1],
           data.thalach[data.target==1],
            c="salmon")
 # scatter with negative examples
plt.scatter(data.age[data.target==0],
           data.thalach[data.target==0],
            c="blue")
# add some helpful information 
plt.title('Heart Disease in function of Age and Max Heart Rate')
plt.xlabel('age')
plt.ylabel('max heart rate')
plt.legend(['Disease','No Disease'])

# correlation  matrix 
corr_matrix=data.corr()
fig,axes=plt.subplots(figsize=(15,15))
axes=sns.heatmap(corr_matrix,
             annot=True,
             linewidths=0.5,
             fmt='.2f',
             cmap="YlGnBu");
bottom,top=axes.get_ylim()
axes.set_ylim(bottom +0.5,top-0.5)




data.drop('target',axis=1).corrwith(data.target).plot(kind= 'bar' , grid =True , figsize=(12,8), title="Correlation with target" )

catagorical_val




#  applying logistic regression 
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
def print_score(clf,X_train,y_train,X_test,y_test,train=True):
    if train:
        pred=clf.predict(X_train)
        clf_report=pd.DataFrame(classification_report(y_train,pred,output_dict=True))
        print('Train result: /n==============================================')
        print(f'Accuracy report : /n {accuracy_score(y_train,pred)*100:.2f}%')
        print('_________________________________________________________')
        print(f'classification report /n {clf_report}')
        print('_________________________________________________________')
        print(f'confusion matrix /n {confusion_matrix(y_train,pred)}')
    elif train==False:
        pred=clf.predict(X_test)
        clf_report=pd.DataFrame(classification_report(y_test,pred,output_dict=True))
        print('Test result: /n==============================================')
        print(f'Accuracy report : /n {accuracy_score(y_test,pred)*100:.2f}%')
        print('_________________________________________________________')
        print(f'classification report /n {clf_report}')
        print('_________________________________________________________')
        print(f'confusion matrix /n {confusion_matrix(y_test,pred)}')

# spplitting data into training and testing sets 
from sklearn.model_selection import train_test_split
X = dataset.drop('target', axis=1)
y = dataset.target
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)


#  print the classification report of our logistic regression model
from sklearn.linear_model import LogisticRegression

lr_clf=LogisticRegression(solver='liblinear')
lr_clf.fit(X_train,y_train)
print_score(lr_clf, X_train, y_train, X_test, y_test, train=True)
print_score(lr_clf, X_train, y_train, X_test, y_test, train=False)

test_score=accuracy_score(y_test,lr_clf.predict(X_test))*100
train_score=accuracy_score(y_train,lr_clf.predict(X_train))*100
result_data=pd.DataFrame(data=[['Logistic Regression',train_score,test_score]],columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])

result_data
